Accuracy vs Precision
=====================

When producing data, key considerations include accuracy and precision. 

Accuracy is how close to the truth a given value is. 

Precision is the level of detail included in the value. 

For example, a boxer might step on the scales and record a value of 87kg. If the boxer’s true weight is 87.43kg, then the scales are accurate to +/- 1kg, and have a degree of precision of 1kg. If the scales were to record a weight of 98.7285kg, they would have a high degree of precision, but a low degree of accuracy. 

For data standards, this concept can be applied to other concepts as well. For example, if an event is described as “Usually happening every Monday at 9am” then its degree of accuracy is relatively high (because the potential for it to not happen is described by the word “usually”), but its precision is relatively low (because it doesn’t tell us under what conditions it might not be happening). Conversely, an event that is described as happening on Monday 3rd May 2021 at 9am is very precise, but may not be accurate if the event doesn’t actually happen on bank holidays. 

Conveying the level of precision in a data standard (as part of the design, or the metadata) can be important for ensuring that its accuracy is understood by data users. Typically, the more precise data needs to be, the higher the costs involved in creating it accurately. 

